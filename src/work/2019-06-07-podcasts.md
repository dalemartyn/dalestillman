---
title: "Podcasts"
date: 2020-06-06T12:00:00+01:00
tagline: "A single page web app built with React and Netlify functions."
image:
  json: /podcasts/podcasts-tablet.json
color_light: "#00BCD4"
color_dark: "#00ACC1"
---

I created this [Podcasts][1] web app as an excuse to build something with React. And a single-page app architecture makes sense for a podcast app, to allow media to play as you browse.

The app uses React Router v6 for navigation, which has a new React Hooks-based API which is really nice to work with. I used Reacts in-built reducers (`useReducer`) along with the Context API to manage my app state. React's reducers work similarly to Redux, but are guaranteed to have forward compatibility with the upcoming Suspense API and Concurrent Mode. [Dan Abramov's two egghead.io courses][2] on Redux are an excellent resource for learning how reducers work.

<figure>
  <div class="c-image-background u-rounded">
    {% image "/podcasts/podcasts-home-page.json" %}
  </div>
</figure>

For the backend, I am using Netlify functions which run on AWS lambda. This allows the app to read any RSS feed, without running into cross-origin issues. To improve performance, I am using an RSS parser that supports streams, to that I can read the first 30 episodes from the RSS feed without downloading the whole feed. This makes a feed to load in seconds, even for feeds over 5MB in size such as [Javascript Jabber][4].

<figure>
  <div class="c-image-background u-rounded">
    {% image "/podcasts/podcasts-category-page.json" %}
  </div>
</figure>

One of the trickiest parts was working around the "[impedance mismatch][5]" between the React programming model and the browser's native [audio element][6]. I initially wanted to have the audio element be driven by the app state, however, the element can also be controlled by the browser. Media can be controlled using laptop keyboards or phone lock screens/notifications. Doing so made the app buggy. A better approach turned out to be to let the audio element handle its state, and use event listeners to update the app state to allow the UI can reflect the state of the audio element. To do this, I had to be able to call the `play()` and `pause()` methods on the audio element from anywhere in the app. I made the audio element available globally using `useRef` with the Context API.

- [Podcasts app][1]
- [Github repo][2]

[1]: https://podcasts.dalestillman.com "Podcasts by Dale"
[2]: https://github.com/dalemartyn/podcast-player "Podcast Player on Github"
[3]: https://egghead.io/instructors/dan-abramov
[4]: https://podcasts.dalestillman.com/podcast?rss=https%3A%2F%2Ffeeds.feedwrench.com%2Fjs-jabber.rss "Javascript Jabber on Podcasts"
[5]: https://overreacted.io/making-setinterval-declarative-with-react-hooks/#the-impedance-mismatch
[6]: https://developer.mozilla.org/en-US/docs/Web/HTML/Element/audio
